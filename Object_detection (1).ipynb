{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b69dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19248a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df2b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.call('dir',shell=True)\n",
    "import keras as k\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "classifier=Sequential()\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(120,activation='relu'))\n",
    "classifier.add(Dense(60,activation='relu'))\n",
    "classifier.add(Dense(1,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f154096f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5825 images belonging to 2 classes.\n",
      "Found 1500 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.2113 - accuracy: 0.9156 - val_loss: 0.3186 - val_accuracy: 0.8633\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.2582 - accuracy: 0.8906 - val_loss: 0.3970 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 0.1380 - accuracy: 0.9500 - val_loss: 0.2464 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.1960 - accuracy: 0.9219 - val_loss: 0.2911 - val_accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 0.1845 - accuracy: 0.9156 - val_loss: 0.2770 - val_accuracy: 0.8828\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.1956 - accuracy: 0.9281 - val_loss: 0.4490 - val_accuracy: 0.8203\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.1812 - accuracy: 0.9312 - val_loss: 0.3229 - val_accuracy: 0.8672\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.2075 - accuracy: 0.9187 - val_loss: 0.3617 - val_accuracy: 0.8555\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.1621 - accuracy: 0.9406 - val_loss: 0.3399 - val_accuracy: 0.8633\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 0.1843 - accuracy: 0.9312 - val_loss: 0.2843 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.1871 - accuracy: 0.9375 - val_loss: 0.3627 - val_accuracy: 0.8711\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.2506 - accuracy: 0.8938 - val_loss: 0.2807 - val_accuracy: 0.8516\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 0.1477 - accuracy: 0.9406 - val_loss: 0.3245 - val_accuracy: 0.8633\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.1586 - accuracy: 0.9406 - val_loss: 0.2152 - val_accuracy: 0.8945\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.1718 - accuracy: 0.9438 - val_loss: 0.2194 - val_accuracy: 0.8984\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 0.1207 - accuracy: 0.9625 - val_loss: 0.2108 - val_accuracy: 0.9141\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.1268 - accuracy: 0.9656 - val_loss: 0.2184 - val_accuracy: 0.9062\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.1132 - accuracy: 0.9531 - val_loss: 0.2007 - val_accuracy: 0.9258\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.1436 - accuracy: 0.9531 - val_loss: 0.3240 - val_accuracy: 0.8867\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: 0.3516 - val_accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11c9bb08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\sathya sandha\\Downloads\\data\\train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\sathya sandha\\Downloads\\data\\test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "classifier.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=8,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dbdf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sathya sandha\\Downloads\\data\\assets\n"
     ]
    }
   ],
   "source": [
    "classifier.save(r'C:\\Users\\sathya sandha\\Downloads\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d861e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(r'C:\\Users\\sathya sandha\\Downloads\\data')\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "img=cv2.imread(r'C:\\Users\\sathya sandha\\Downloads\\data\\validate\\road.jpg')\n",
    "imgg=cv2.imread(r'C:\\Users\\sathya sandha\\Downloads\\data\\validate\\ss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "593e3fad",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\core\\src\\array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e875593a7b51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"road\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\core\\src\\array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"road\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dc7a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"car\",imgg)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47676d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-ba5b84937ad9>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "img=cv2.resize(img,(64,64))\n",
    "img=np.reshape(img,[1,64,64,3])\n",
    "imgg=cv2.resize(imgg,(64,64))\n",
    "imgg=np.reshape(imgg,[1,64,64,3])\n",
    "pred1=model.predict_classes(img)\n",
    "pred2=model.predict_classes(imgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879518b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "print(pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf02844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "print(pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5293409",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ba2ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd7c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice(a):\n",
    "    if(a==[[1]]):\n",
    "        mytext = 'There is an obstacle'  \n",
    "        language = 'en'\n",
    "        myobj = gTTS(text=mytext, lang=language, slow=True)\n",
    "        myobj.save(\"vechclee.mp3\")\n",
    "        os.system(\"start vechclee.mp3\")\n",
    "    else:\n",
    "        mytext = 'There is no obstacle'  \n",
    "        language = 'en'\n",
    "        myobj = gTTS(text=mytext, lang=language, slow=True)\n",
    "        myobj.save(\"novehi.mp3\")\n",
    "        os.system(\"start novehi.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14089dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
